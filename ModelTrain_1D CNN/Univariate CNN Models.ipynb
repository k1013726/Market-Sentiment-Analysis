{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv1D, MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 該該函數將序列數據分割成樣本\n",
    "def split_sequence(sequence, sw_width, n_features):\n",
    "    '''\n",
    "    這個簡單的示例，通過for循環實現有重疊截取數據，滑動步長爲1，滑動窗口寬度爲sw_width。\n",
    "    以後的文章，會介紹使用yield方法來實現特定滑動步長的滑動窗口的實例。\n",
    "    '''\n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(len(sequence)):\n",
    "        # 獲取單個樣本中最後一個元素的索引，因爲python切片前閉後開，索引從0開始，所以不需要-1\n",
    "        end_element_index = i + sw_width\n",
    "        # 如果樣本最後一個元素的索引超過了序列索引的最大長度，說明不滿足樣本元素個數，則這個樣本丟棄\n",
    "        if end_element_index > len(sequence) - 1:\n",
    "            break\n",
    "        # 通過切片實現步長爲1的滑動窗口截取數據組成樣本的效果\n",
    "        seq_x, seq_y = sequence[i:end_element_index], sequence[end_element_index]\n",
    "        \n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "        \n",
    "        process_X, process_y = np.array(X), np.array(y)\n",
    "        process_X = process_X.reshape((process_X.shape[0], process_X.shape[1], n_features))\n",
    "    \n",
    "    print('split_sequence:\\nX:\\n{}\\ny:\\n{}\\n'.format(np.array(X), np.array(y)))\n",
    "    print('X_shape:{},y_shape:{}\\n'.format(np.array(X).shape, np.array(y).shape))\n",
    "    print('train_X:\\n{}\\ntrain_y:\\n{}\\n'.format(process_X, process_y))\n",
    "    print('train_X.shape:{},trian_y.shape:{}\\n'.format(process_X.shape, process_y.shape))\n",
    "    return process_X, process_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oned_cnn_model(sw_width, n_features, X, y, test_X, epoch_num, verbose_set):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # 對於一維卷積來說，data_format='channels_last'是默認配置，該API的規則如下：\n",
    "    # 輸入形狀爲：(batch, steps, channels)；輸出形狀爲：(batch, new_steps, filters)，padding和strides的變化會導致new_steps變化\n",
    "    # 如果設置爲data_format = 'channels_first'，則要求輸入形狀爲： (batch, channels, steps).\n",
    "    model.add(Conv1D(filters=64, kernel_size=2, activation='relu',\n",
    "                     strides=1, padding='valid', data_format='channels_last',\n",
    "                     input_shape=(sw_width, n_features)))\n",
    "    \n",
    "    # 對於一維池化層來說，data_format='channels_last'是默認配置，該API的規則如下：\n",
    "    # 3D 張量的輸入形狀爲: (batch_size, steps, features)；輸出3D張量的形狀爲：(batch_size, downsampled_steps, features)\n",
    "    # 如果設置爲data_format = 'channels_first'，則要求輸入形狀爲：(batch_size, features, steps)\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=None, padding='valid', \n",
    "                           data_format='channels_last')) \n",
    "    \n",
    "    # data_format參數的作用是在將模型從一種數據格式切換到另一種數據格式時保留權重順序。默認爲channels_last。\n",
    "    # 如果設置爲channels_last，那麼數據輸入形狀應爲：（batch，…，channels）；如果設置爲channels_first，那麼數據輸入形狀應該爲（batch，channels，…）\n",
    "    # 輸出爲（batch, 之後參數尺寸的乘積）\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Dense執行以下操作：output=activation（dot（input，kernel）+bias），\n",
    "    # 其中,activation是激活函數，kernel是由層創建的權重矩陣，bias是由層創建的偏移向量（僅當use_bias爲True時適用）。\n",
    "    # 2D 輸入：(batch_size, input_dim)；對應 2D 輸出：(batch_size, units)\n",
    "    model.add(Dense(units=50, activation='relu',\n",
    "                use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros',))\n",
    "    \n",
    "    # 因爲要預測下一個時間步的值，因此units設置爲1\n",
    "    model.add(Dense(units=1))\n",
    "    \n",
    "    # 配置模型\n",
    "    model.compile(optimizer='adam', loss='mse',\n",
    "                 metrics=['accuracy'], loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None)\n",
    "    \n",
    "    print('\\n',model.summary())\n",
    "    # X爲輸入數據，y爲數據標籤；batch_size：每次梯度更新的樣本數，默認爲32。\n",
    "    # verbose: 0,1,2. 0=訓練過程無輸出，1=顯示訓練過程進度條，2=每訓練一個epoch打印一次信息\n",
    "    \n",
    "    history = model.fit(X, y, batch_size=32, epochs=epoch_num, verbose=verbose_set)\n",
    "    \n",
    "    \n",
    "    yhat = model.predict(test_X, verbose=0)\n",
    "    print('\\nyhat:', yhat)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_sequence:\n",
      "X:\n",
      "[[10 20 30]\n",
      " [20 30 40]\n",
      " [30 40 50]\n",
      " [40 50 60]\n",
      " [50 60 70]\n",
      " [60 70 80]]\n",
      "y:\n",
      "[40 50 60 70 80 90]\n",
      "\n",
      "X_shape:(6, 3),y_shape:(6,)\n",
      "\n",
      "train_X:\n",
      "[[[10]\n",
      "  [20]\n",
      "  [30]]\n",
      "\n",
      " [[20]\n",
      "  [30]\n",
      "  [40]]\n",
      "\n",
      " [[30]\n",
      "  [40]\n",
      "  [50]]\n",
      "\n",
      " [[40]\n",
      "  [50]\n",
      "  [60]]\n",
      "\n",
      " [[50]\n",
      "  [60]\n",
      "  [70]]\n",
      "\n",
      " [[60]\n",
      "  [70]\n",
      "  [80]]]\n",
      "train_y:\n",
      "[40 50 60 70 80 90]\n",
      "\n",
      "train_X.shape:(6, 3, 1),trian_y.shape:(6,)\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 2, 64)             192       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 1, 64)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 50)                3250      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,493\n",
      "Trainable params: 3,493\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      " None\n",
      "\n",
      "yhat: [[101.58544]]\n",
      "\n",
      "train_acc:0.0 \n",
      "train_loss:75.19357600126555\n"
     ]
    }
   ],
   "source": [
    "train_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "sw_width = 3\n",
    "n_features = 1\n",
    "epoch_num = 1000\n",
    "verbose_set = 0\n",
    "\n",
    "train_X, train_y = split_sequence(train_seq, sw_width, n_features)\n",
    "\n",
    "# 預測\n",
    "x_input = np.array([70, 80, 90])\n",
    "x_input = x_input.reshape((1, sw_width, n_features))\n",
    "\n",
    "model, history = oned_cnn_model(sw_width, n_features, train_X, train_y, x_input, epoch_num, verbose_set)\n",
    "\n",
    "print('\\ntrain_acc:%s'%np.mean(history.history['accuracy']), '\\ntrain_loss:%s'%np.mean(history.history['loss']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
