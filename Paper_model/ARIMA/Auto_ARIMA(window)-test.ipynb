{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima import auto_arima\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建時間窗口的訓練集數據\n",
    "def create_dataset(closing_prices, time_window):\n",
    "    features,targets = [],[]\n",
    "    for i in range(len(closing_prices) - time_window):\n",
    "        features.append(closing_prices.iloc[i:i+time_window])\n",
    "        targets.append(closing_prices.iloc[i+time_window])   \n",
    "    return np.array(features),np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = pd.read_csv(f'../Data/BTCUSD-all.csv')\n",
    "# # dataset= np.log(dataset[\"Close\"])\n",
    "# train_data, test_data = train_test_split(dataset[\"Close\"], test_size=7, shuffle=False)\n",
    "\n",
    "# # Take the logarithm\n",
    "# # train_data = np.log(train_data)\n",
    "# # test_data= np.log(test_data)\n",
    "\n",
    "# # Calculate mean and standard deviation\n",
    "# mean = np.mean(train_data)\n",
    "# std = np.std(train_data)*3\n",
    "\n",
    "# # Z-score normalization\n",
    "# standardized_train = (train_data - mean) / std\n",
    "# standardized_test=(test_data- mean)/ std\n",
    "# print(train_data.shape,test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳模型參數:ARIMA (0, 1, 0)\n",
      "MAE train:322.4943 test:10901.0974\n",
      "RMSE train:767.7009 test:12242.3494\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(f'../Data/BTCUSD-all.csv') \n",
    "train_data, test_data = train_test_split(data['Close'], test_size=0.2, shuffle=False)\n",
    "\n",
    "lb=12\n",
    "trainX, trainY = create_dataset(train_data, lb)\n",
    "testX, testY = create_dataset(test_data, lb)\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "best_model = None\n",
    "best_rmse = np.inf\n",
    "\n",
    "# for train_index, val_index in tscv.split(trainY):\n",
    "#     train_val_data, val_data = trainY[train_index], trainY[val_index]    \n",
    "#     model = auto_arima(train_val_data,exogenous=trainX[train_index],max_p=20,max_q=20,seasonal=False)   \n",
    "#     forecast = model.predict(len(val_data))\n",
    "#     rmse = np.sqrt(mean_squared_error(val_data, forecast))\n",
    "#     if rmse < best_rmse:\n",
    "#         best_rmse = rmse\n",
    "#         best_model = model\n",
    "# best_model.fit(trainY)\n",
    "\n",
    "best_model = auto_arima(trainY,exogenous=trainX,max_p=20,max_q=20,seasonal=False)\n",
    "best_model.fit(trainY)\n",
    "best_model_params = best_model.get_params()['order']\n",
    "print(\"最佳模型參數:ARIMA\", best_model_params)\n",
    "\n",
    "\n",
    "# forecast\n",
    "test_forecast = best_model.predict(n_periods=len(testY))\n",
    "\n",
    "\n",
    "test_data_mae=mean_absolute_error(testY,test_forecast)\n",
    "test_data_rmse=mean_squared_error(testY,test_forecast)**0.5        \n",
    "      \n",
    "\n",
    "# predict train\n",
    "train_forecast = best_model.predict_in_sample()    \n",
    "\n",
    "train_data_mae=mean_absolute_error(trainY,train_forecast)\n",
    "train_data_rmse=mean_squared_error(trainY,train_forecast)**0.5\n",
    "\n",
    "\n",
    "print(f'MAE train:{train_data_mae:.4f} test:{test_data_mae:.4f}')   \n",
    "print(f'RMSE train:{train_data_rmse:.4f} test:{test_data_rmse:.4f}')         \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nptu\\Documents\\GitHub\\Market-Sentiment-Analysis\\Paper_model\\ARIMA\\Auto_ARIMA(window)-test.ipynb 儲存格 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nptu/Documents/GitHub/Market-Sentiment-Analysis/Paper_model/ARIMA/Auto_ARIMA%28window%29-test.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m best_model\u001b[39m.\u001b[39;49mpredict(\u001b[39m2\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\nptu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pmdarima\\arima\\arima.py:796\u001b[0m, in \u001b[0;36mARIMA.predict\u001b[1;34m(self, n_periods, X, return_conf_int, alpha, **kwargs)\u001b[0m\n\u001b[0;32m    793\u001b[0m arima \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39marima_res_\n\u001b[0;32m    794\u001b[0m end \u001b[39m=\u001b[39m arima\u001b[39m.\u001b[39mnobs \u001b[39m+\u001b[39m n_periods \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 796\u001b[0m f, conf_int \u001b[39m=\u001b[39m _seasonal_prediction_with_confidence(\n\u001b[0;32m    797\u001b[0m     arima_res\u001b[39m=\u001b[39;49marima,\n\u001b[0;32m    798\u001b[0m     start\u001b[39m=\u001b[39;49marima\u001b[39m.\u001b[39;49mnobs,\n\u001b[0;32m    799\u001b[0m     end\u001b[39m=\u001b[39;49mend,\n\u001b[0;32m    800\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    801\u001b[0m     alpha\u001b[39m=\u001b[39;49malpha)\n\u001b[0;32m    803\u001b[0m \u001b[39mif\u001b[39;00m return_conf_int:\n\u001b[0;32m    804\u001b[0m     \u001b[39m# The confidence intervals may be a Pandas frame if it comes from\u001b[39;00m\n\u001b[0;32m    805\u001b[0m     \u001b[39m# SARIMAX & we want Numpy. We will to duck type it so we don't add\u001b[39;00m\n\u001b[0;32m    806\u001b[0m     \u001b[39m# new explicit requirements for the package\u001b[39;00m\n\u001b[0;32m    807\u001b[0m     \u001b[39mreturn\u001b[39;00m f, check_array(conf_int, force_all_finite\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\nptu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pmdarima\\arima\\arima.py:205\u001b[0m, in \u001b[0;36m_seasonal_prediction_with_confidence\u001b[1;34m(arima_res, start, end, X, alpha, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m     conf_int[:, \u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m f \u001b[39m+\u001b[39m q \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39msqrt(var)\n\u001b[0;32m    204\u001b[0m y_pred \u001b[39m=\u001b[39m check_endog(f, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, preserve_series\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> 205\u001b[0m conf_int \u001b[39m=\u001b[39m check_array(conf_int, copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, dtype\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    207\u001b[0m \u001b[39mreturn\u001b[39;00m y_pred, conf_int\n",
      "File \u001b[1;32mc:\\Users\\nptu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    918\u001b[0m         )\n\u001b[0;32m    920\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 921\u001b[0m         _assert_all_finite(\n\u001b[0;32m    922\u001b[0m             array,\n\u001b[0;32m    923\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    924\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    925\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    926\u001b[0m         )\n\u001b[0;32m    928\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mc:\\Users\\nptu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    145\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    148\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m     )\n\u001b[1;32m--> 161\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "best_model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
